# ğŸ§  NLP_With_DL_DeepDive  
*A personal journey through modern Natural Language Processing using Deep Learning*

Hi there! ğŸ‘‹ I'm Samhita, and this repository is a reflection of my deep dive into the world of **Natural Language Processing (NLP)** using deep learning.

When I first started exploring NLP, I wanted to go beyond theory â€” to **build**, **experiment**, and truly understand how models learn language. This collection of projects represents that hands-on journey â€” from simple word embeddings to advanced sequence modeling with RNNs and PyTorch.

Each folder here tells a story â€” a problem I explored, a model I built, and a lesson I learned along the way.

---

## ğŸ§­ What You'll Find Here

| Folder | Description |
|--------|-------------|
| `word2vec_skipgram/` | My first step into representation learning â€” building the Skip-Gram model with negative sampling from scratch |
| `vectorspeak_word2vec_skipgram/` | An extension to compare how different architectures learn embeddings â€” because visualizing words is powerful |
| `ffnn_sentiment_analysis_numpy_pytorch/` | A practical dive into sentiment analysis using Feedforward Neural Networks â€” comparing pure NumPy and PyTorch versions |
| `ner_rnn_conll2003_pytorch/` | A full-scale sequence labeling challenge â€” implementing 7 RNN variants for Named Entity Recognition on CoNLL-2003 |

---

## âš™ï¸ Tools & Technologies

```bash
Python 3.x
NumPy
PyTorch
Matplotlib
NLTK / Gensim
